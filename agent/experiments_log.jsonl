{"phase": "phase1", "experiment_name": "data_augmentation", "config": {"configs_tested": [{"model": "qwen2.5:7b-instruct", "top_k": 6, "name": "baseline"}, {"model": "qwen2.5:7b-instruct", "top_k": 10, "name": "expanded"}, {"model": "mistral:7b-instruct", "top_k": 6, "name": "mistral_baseline"}]}, "metrics": {"datasets_created": 3, "total_samples": 9}, "duration_seconds": 88.87656545639038, "timestamp": "2025-09-06T12:33:47.836026", "notes": "Generated multiple augmented datasets for robustness testing"}
{"phase": "phase2", "experiment_name": "embedding_test_intfloat_multilingual-e5-large", "config": {"embedding_model": "intfloat/multilingual-e5-large", "chunk_chars": 900, "overlap_chars": 120}, "metrics": {"faithfulness": 0.6333333333333333, "answer_relevancy": 0.05194870593874262}, "duration_seconds": 204.55960035324097, "timestamp": "2025-09-06T12:37:12.395948", "notes": "Embedding model evaluation: intfloat/multilingual-e5-large"}
{"phase": "phase2", "experiment_name": "embedding_test_sentence-transformers_paraphrase-multilingual-mpnet-base-v2", "config": {"embedding_model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "chunk_chars": 900, "overlap_chars": 120}, "metrics": {"faithfulness": 0.6666666666666666, "answer_relevancy": 0.023627047281835383}, "duration_seconds": 169.67220091819763, "timestamp": "2025-09-06T12:40:02.073680", "notes": "Embedding model evaluation: sentence-transformers/paraphrase-multilingual-mpnet-base-v2"}
{"phase": "phase2", "experiment_name": "embedding_test_intfloat_multilingual-e5-base", "config": {"embedding_model": "intfloat/multilingual-e5-base", "chunk_chars": 900, "overlap_chars": 120}, "metrics": {"faithfulness": 0.6333333333333333, "answer_relevancy": 0.0437904617548047}, "duration_seconds": 139.514098405838, "timestamp": "2025-09-06T12:42:21.590359", "notes": "Embedding model evaluation: intfloat/multilingual-e5-base"}
{"phase": "phase2", "experiment_name": "embedding_test_sentence-transformers_LaBSE", "config": {"embedding_model": "sentence-transformers/LaBSE", "chunk_chars": 900, "overlap_chars": 120}, "metrics": {"faithfulness": 0.5925925925925926, "answer_relevancy": 0.040721179024831224}, "duration_seconds": 302.67974758148193, "timestamp": "2025-09-06T12:47:24.284335", "notes": "Embedding model evaluation: sentence-transformers/LaBSE"}
{"phase": "phase3", "experiment_name": "generation_test_qwen2.5_7b-instruct", "config": {"generation_model": "qwen2.5:7b-instruct", "top_k": 6}, "metrics": {"faithfulness": 0.6666666666666666, "answer_relevancy": 0.043807902000154365}, "duration_seconds": 52.30874705314636, "timestamp": "2025-09-06T12:48:16.610943", "notes": "Generation model evaluation: qwen2.5:7b-instruct"}
{"phase": "phase3", "experiment_name": "generation_test_mistral_7b-instruct", "config": {"generation_model": "mistral:7b-instruct", "top_k": 6}, "metrics": {"faithfulness": 0.5, "answer_relevancy": 0.04558254942682786}, "duration_seconds": 51.65229058265686, "timestamp": "2025-09-06T12:49:08.264822", "notes": "Generation model evaluation: mistral:7b-instruct"}
{"phase": "phase3", "experiment_name": "generation_test_gemma2_7b-instruct", "config": {"generation_model": "gemma2:7b-instruct", "top_k": 6}, "metrics": {"faithfulness": 0.625, "answer_relevancy": 0.04367722248608879}, "duration_seconds": 48.75977063179016, "timestamp": "2025-09-06T12:49:57.026265", "notes": "Generation model evaluation: gemma2:7b-instruct"}
